<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<meta content="Projects by Saurav Sengupta." name="description"/>
<link href="/feeds/all.atom.xml" rel="alternate" title="Saurav Sengupta Full Atom Feed" type="application/atom+xml"/>
<title>Projects - Saurav Sengupta</title>
<!-- KaTeX -->
<link crossorigin="anonymous" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0-beta1/katex.min.css" integrity="sha384-VEnyslhHLHiYPca9KFkBB3CMeslnM9CzwjxsEbZTeA21JBm7tdLwKoZmCt3cZTYD" rel="stylesheet"/>
<script crossorigin="anonymous" integrity="sha384-O4hpKqcplNCe+jLuBVEXC10Rn1QEqAmX98lKAIFBEDxZI0a+6Z2w2n8AEtQbR4CD" src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0-beta1/katex.min.js"></script>
<script crossorigin="anonymous" integrity="sha384-IiI65aU9ZYub2MY9zhtKd1H2ps7xxf+eb2YFG9lX6uRqpXCvBTOidPRCXCrQ++Uc" src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0-beta1/contrib/auto-render.min.js"></script>
<link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet"/>
<link href="/theme/css/pure.css?v=0.1.0" rel="stylesheet"/>
<!-- for pelican_dynamic plugin -->
<!-- end pelican_dynamic -->
</head>
<body>
<div class="pure-g-r" id="layout">
<div class="sidebar pure-u">
<div class="cover-img" style="background-image: url('/images/home-bg.jpg');">
<div class="cover-body">
<header class="header">
<h1 class="brand-main"><a href="/">Saurav Sengupta</a></h1>
<p class="tagline">Deep learning and data science</p>
<p class="links"><a href="/">About</a></p>
<p class="links"><a href="/projects.html">Projects</a></p>
<p class="links"><a href="/blog/">Blog</a></p>
<p class="links"><a href="/files/cv.pdf">Resume</a></p>
<p class="social">
<a href="https://github.com/ssen7/">
<i class="fa fa-github fa-2x"></i>
</a>
<a href="https://twitter.com/sauravsen111">
<i class="fa fa-twitter fa-2x"></i>
</a>
<a href="https://www.linkedin.com/in/saurav-sengupta/">
<i class="fa fa-linkedin fa-2x"></i>
</a>
<a href="/files/SauravSenguptaCV2019.pdf">
<i class="fa fa-file-text fa-2x"></i>
</a>
<a href="/feeds/all.atom.xml">
<i class="fa fa-rss fa-2x"></i>
</a>
</p>
</header>
</div>
</div>
</div> <div class="pure-u-1">
<div class="content">
<h1 class="content-subhead">Projects</h1>
<h2>Building CNNs to classify duodenal biopsy images into diseases – Child Health Research Center, <span class="caps">UVA</span></h2>
<ul>
<li>We use Convolutional Neural Networks (<span class="caps">CNN</span>) to classify high resolution digitized biopsy images into Celiac Disease, Environmental Enteropathy and Normal tissues. </li>
<li>We are using existing architectures like Resnet34 and Resnet50 in our analysis, since they are the deep and perform well on a diverse set of images. We use the fabulous fastai library.</li>
<li>We are also using metabolomics data to find important features of classification.</li>
<li>Funded and supported by the <strong>Bill and Melinda Gates</strong> foundation and the <strong>Aga Khan University</strong>.</li>
<li><a href="https://github.com/UVA-DSI-2019-Capstones/CHRC">GitHub</a>.</li>
</ul>
<h2>(Ongoing) Self Drawing Agent (Reinforcement Learning Project)</h2>
<ul>
<li>A text to image creator. Our agent will take a number in text format and draw an image equivalent of that number. </li>
<li>This agent could be a starting point for a creative tool that can draws illustrations based on text or other image inputs as reference. </li>
<li>We use OpenAI gym based environment that gives us a way to train agents to draw ImageNet objects on a black-and-white canvas. </li>
<li>Use <span class="caps">MNIST</span> dataset to develop a reward function that guides our agent online while drawing the image equivalents. </li>
<li>Use Neural Network based classification to build our reward function. Our reward function should be able to capture not just a single image equivalent of a number but also the variance in original dataset and use that variance to recreate multiple image equivalents for each number. </li>
<li>Inspired by previous work undertaken by <a href="https://deepmind.com/blog/learning-to-generate-images">DeepMind</a> where they trained a robot to create images and train a virtual agent to draw the images.</li>
</ul>
<h2>Music Genre classification</h2>
<ul>
<li>Created <span class="caps">EC2</span> <span class="caps">AWS</span> instance to get data from the Million Song Dataset. </li>
<li>Wrote scripts to get data from S3 bucket and run Jupyter notebooks on <span class="caps">EC2</span>.</li>
<li>Used Text mining on song lyrics and song features to predict 13 different genre types. Used feature selection to reduce the number of features and reduce overfitting. 58.6% Accuracy. </li>
<li><a href="https://github.com/ssen7/sys6018-final-project">GitHub</a>.</li>
</ul>
<h2>Modeling brainwave activity</h2>
<ul>
<li>Used Muse™ headset to collect brain activity data in the form of frequency measurements of alpha, beta, gamma, delta and theta waves to classify actions like moving hands, motor imagination.</li>
<li>Found correlation between alpha waves and motion. </li>
<li>Used Logistic Regression for real time modeling and classification of thought and used it to move object in a mobile game environment.</li>
</ul>
<h2>Modeling quality of barbell lifts using accelerometer data</h2>
<ul>
<li>The goal was to use data from accelerometers on the belt, forearm, arm, and dumbbell of 6 participants, to predict how well they do barbell lifts.</li>
<li>Tested accuracy of models built using Tree Algorithm, Random Forest, and Model Stacking using the caret package in R. </li>
<li><a href="https://ssen7.github.io/practical-machine-learning-coursera/">GitHub Pages</a> Link.</li>
</ul>
<footer class="footer">
</footer> </div>
</div>
</div>
<script>
        renderMathInElement(document.body);
    </script>
<!-- for pelican_dynamic plugin -->
</body>
</html>