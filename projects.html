<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="description" content="Projects by Saurav Sengupta." />


        <link rel="alternate"  href="/feeds/all.atom.xml" type="application/atom+xml" title="Saurav Sengupta Full Atom Feed"/>

        <title>Projects - Saurav Sengupta</title>


    <!-- KaTeX -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0-beta1/katex.min.css" integrity="sha384-VEnyslhHLHiYPca9KFkBB3CMeslnM9CzwjxsEbZTeA21JBm7tdLwKoZmCt3cZTYD" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0-beta1/katex.min.js" integrity="sha384-O4hpKqcplNCe+jLuBVEXC10Rn1QEqAmX98lKAIFBEDxZI0a+6Z2w2n8AEtQbR4CD" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0-beta1/contrib/auto-render.min.js" integrity="sha384-IiI65aU9ZYub2MY9zhtKd1H2ps7xxf+eb2YFG9lX6uRqpXCvBTOidPRCXCrQ++Uc" crossorigin="anonymous"></script>

    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.1.0/css/font-awesome.min.css" />
    <link rel="stylesheet" href="/theme/css/pure.css?v=0.1.0" />

    <!-- for pelican_dynamic plugin -->
    <!-- end pelican_dynamic -->

</head>

<body>
<div class="pure-g-r" id="layout">
<div class="sidebar pure-u">
    <div class="cover-img" style="background-image: url('/images/home-bg.jpg');">
        <div class="cover-body">
            <header class="header">
                    <h1 class="brand-main"><a href="/">Saurav Sengupta</a></h1>
                    <p class="tagline">Masters of Data Science at DSI, UVA.</p>
                    <p class="links"><a href="/">About</a></p>
                    <p class="links"><a href="/projects.html">Projects</a></p>
                    <p class="links"><a href="/blog/">Blog</a></p>
                    <p class="links"><a href="/publications.html">Publications</a></p>
                    <p class="links"><a href="/files/cv.pdf">Resume</a></p>
                    <p class="social">
                        <a href="https://github.com/ssen7/">
                            <i class="fa fa-github fa-2x"></i>
                        </a>
                        <a href="https://twitter.com/sauravsen111">
                            <i class="fa fa-twitter fa-2x"></i>
                        </a>
                        <a href="https://www.linkedin.com/in/saurav-sengupta/">
                            <i class="fa fa-linkedin fa-2x"></i>
                        </a>
                        <a href="/files/SauravSenguptaCV2019.pdf">
                            <i class="fa fa-file-text fa-2x"></i>
                        </a>
                        <a href="/feeds/all.atom.xml">
                            <i class="fa fa-rss fa-2x"></i>
                        </a>
                    </p>
            </header>
        </div>
    </div>
</div>    <div class="pure-u-1">
        <div class="content">
            <h1 class="content-subhead">Projects</h1>
            <h2>Building CNNs to classify duodenal biopsy images into diseases – Child Health Research Center, <span class="caps">UVA</span></h2>
<ul>
<li>We use <strong>Convolutional Neural Networks</strong> (<span class="caps">CNN</span>) to classify high resolution digitized biopsy images into Celiac Disease, Environmental Enteropathy and Normal&nbsp;tissues. </li>
<li>We are using existing architectures like Resnet34 and Resnet50 in our analysis, since they are the deep and perform well on a diverse set of images. We use the fabulous <strong>fastai</strong>&nbsp;library.</li>
<li>We are also using metabolomics data to find important features of&nbsp;classification.</li>
<li>Funded and supported by the <strong>Bill and Melinda Gates</strong> foundation and the <strong>Aga Khan University</strong>.</li>
<li><a href="https://github.com/UVA-DSI-2019-Capstones/CHRC">GitHub</a>.</li>
</ul>
<h2>(Ongoing) Self Drawing Agent (Reinforcement Learning&nbsp;Project)</h2>
<ul>
<li>A text to image creator. Our agent will take a number in text format and draw an image equivalent of that&nbsp;number. </li>
<li>This agent could be a starting point for a creative tool that can draws illustrations based on text or other image inputs as&nbsp;reference. </li>
<li>We use <strong>OpenAI gym</strong> based environment that gives us a way to train agents to draw ImageNet objects on a black-and-white&nbsp;canvas. </li>
<li>Use <span class="caps">MNIST</span> dataset to develop a reward function that guides our agent online while drawing the image&nbsp;equivalents. </li>
<li>Use Neural Network based classification to build our reward function. Our reward function should be able to capture not just a single image equivalent of a number but also the variance in original dataset and use that variance to recreate multiple image equivalents for each&nbsp;number. </li>
<li>Inspired by previous work undertaken by <strong><a href="https://deepmind.com/blog/learning-to-generate-images">DeepMind</a></strong> where they trained a robot to create images and train a virtual agent to draw the&nbsp;images.</li>
</ul>
<h2>(Ongoing) Distracted driver image recognition using Bayesian Neural&nbsp;Networks</h2>
<ul>
<li>Systems that can detect if a driver is still attentive enough can add to&nbsp;security. </li>
<li><span class="caps">CNN</span> results are bound by the kind of data we feed to it. This can become dangerous in cases where inattentive drivers are wrongly&nbsp;identified. </li>
<li>Bayesian Neural Nets (<span class="caps">BNN</span>) incorporate a measure of uncertainty that can be important in decision making&nbsp;systems.</li>
<li>The data we will be using for this project is <a href="https://www.kaggle.com/c/state-farm-distracted-driver-detection/data">Distracted Driving imageset</a> from&nbsp;StateFarm. </li>
<li>Use a <span class="caps">BNN</span> to model the data. <span class="caps">BNN</span> extends the standard neural nets by using bayesian inference to make better estimates of weights and&nbsp;biases.</li>
</ul>
<h2>Music Genre&nbsp;classification</h2>
<ul>
<li>Created <strong><span class="caps">EC2</span> <span class="caps">AWS</span></strong> instance to get data from the <a href="https://aws.amazon.com/datasets/million-song-dataset/">Million Song Dataset</a>. </li>
<li>Wrote scripts to get data from <strong>S3 bucket</strong> and run Jupyter notebooks on <span class="caps">EC2</span>.</li>
<li>Used <strong>Text Mining</strong> on song lyrics and song features to predict 13 different genre types. Used feature selection to reduce the number of features and reduce overfitting. 58.6%&nbsp;Accuracy. </li>
<li><a href="https://github.com/ssen7/sys6018-final-project">GitHub</a>.</li>
</ul>
<h2>Modeling brainwave&nbsp;activity</h2>
<ul>
<li>Used <strong>Muse™ headset</strong> to collect brain activity data in the form of frequency measurements of alpha, beta, gamma, delta and theta waves to classify actions like moving hands, motor&nbsp;imagination.</li>
<li>Found correlation between alpha waves and&nbsp;motion. </li>
<li>Used <strong>Logistic Regression</strong> for real time modeling and classification of thought and used it to move object in a mobile game&nbsp;environment.</li>
</ul>
<h2>Modeling quality of barbell lifts using accelerometer&nbsp;data</h2>
<ul>
<li>The goal was to use data from accelerometers on the belt, forearm, arm, and dumbbell of 6 participants, to predict how well they do barbell&nbsp;lifts.</li>
<li>Tested accuracy of models built using <strong>Tree Algorithm</strong>, <strong>Random Forest</strong>, and <strong>Model Stacking</strong> using the <strong>caret</strong> package in&nbsp;R. </li>
<li><a href="https://ssen7.github.io/practical-machine-learning-coursera/">GitHub Pages</a>&nbsp;Link.</li>
</ul>
<footer class="footer">
</footer>        </div>
    </div>
</div>
    <script>
        renderMathInElement(document.body);
    </script>

    <!-- for pelican_dynamic plugin -->



</body>
</html>